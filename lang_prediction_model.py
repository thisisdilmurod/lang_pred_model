# -*- coding: utf-8 -*-
"""lang_prediction_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_ZHD7e05QTEA6Ihm3OnyHmHMN_Dp70_g

## **Predicting Tendency towards Multilingualism with Supervised Learning**

### **Abstract**
Multilingualism refers to the use of more than a single dialect, either regarding to the individual or to the group. Over the past few years, the number of multilingual speakers has increasingly grown all around the globe [1].

### **Introduction**
With the dataset of roughly 100 entries, the supervised learning model will focus on predicting latent multilingualism through a classification algorithm of logistic regression. For the multi-nominal nature of this matter, some specialized handling requires to be done. All of the numeric attributes are given in the same units and scales, meaning that no scaling and transforming of dataset needs to be accomplished to get begin with. Successfully importing every necessary Python library, from NumPy for mathematical operations on arrays to Scikit-learn for machine learning and statistical modeling, the data will be restructed and visualized so as to better contemplate the essential points, such as the mean, the median, the standard deviation, etc. Data is then split into test and training sections with the test sample 20% of the total entries. The use of artificial intelligence will pose a myriad of benefits for people to better understand their likelihood of pursuing languages and thereby acting according to the consequences provided.
"""

# Importing necessary Python libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import plot_confusion_matrix

# Structuring the dataset
ling_data = pd.read_csv('/content/ling_data.csv', header=None)
ling_data.head()

# Understanding the dataset
ling_data.shape
ling_data.describe()

ling_data[6].value_counts()

# Visualizing the dataset
x = ling_data[0]
y = ling_data[6]

plt.scatter(x, y, c=y, cmap='Wistia')
plt.title('Scatter PLot of Logistic Regression')
plt.show()

#Splitting the dataset
x = ling_data.drop(columns=6, axis=1)
y = ling_data[6]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=1)

"""### **Methods**
##### **Data acquisition**
some text
##### **Logistic Regression**
some text for editing and so on $f(x)=\frac{1}{1+e^{x}}$ some text for editing and so on
##### **Model training**
some text
"""

model = LogisticRegression()
model.fit(x_train, y_train)

x_train_predict = model.predict(x_train)
training_data_acc = accuracy_score(x_train_predict, y_train)

"""### **Final results**
some text
"""

print(f'Training data accuracy: {training_data_acc}')

input_data = (17,2,2,2,1,8)
input_data_as_array = np.asarray(input_data)
input_data_reshape = input_data_as_array.reshape(1, -1)
predict = model.predict(input_data_reshape)

if predict[0] == '0':
  print('Intendency to become multilingual')
else:
  print('Tendency to become multilingual')

disp = plot_confusion_matrix(model, x_test, y_test, cmap='Wistia', values_format='.3g')

disp.confusion_matrix

"""### **References**
some text

### **Acknowledgemens**
Professor Rajan Prasad Tripathi, Artificial Intelligence and Machine Learning, Amity University <br> Doctor Danish Ather, Algorithms and Internet of Things, Amity University
"""

