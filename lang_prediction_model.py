# -*- coding: utf-8 -*-
"""lang_prediction_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_ZHD7e05QTEA6Ihm3OnyHmHMN_Dp70_g

## **Predicting Tendency towards Multilingualism with Supervised Learning**

### **Abstract**
Multilingualism refers to the use of more than a single dialect, either regarding the individual or the group. Over the past few years, there has been quite an increase in the number of multilingual speakers around the globe, and thus, the early detection of the potential to learn another language plays an essential role in education as well as further lifestyle. However, the prediction for susceptibility towards multilingualism now heavily relies on conventional measures, leading to the lack of predictive range and statistical modelling inaccuracies. To approach the associated issues of traditional methodologies, we created a supervised learning model with the use of mathematics in Python. Compiling a dataset for a wide range of factors, such as socioeconomic status, ethnicity, culture, age, education, and occupation, we focused the model on analyzing through the classification algorithm of logistic regression. In conclusion, the use of machine learning poses a plethora of advantages for better predicting the likelihood of pursuing additional language and thereby acting according to the provided outcomes. As a result of these benefits, this model can immensely elevate the psychological along with physiological techniques of envisioning latent multilingualism.
"""

# Importing necessary Python libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import plot_confusion_matrix

# Structuring the dataset
ling_data = pd.read_csv('/content/ling_data.csv', header=None)
ling_data.head()

# Understanding the dataset
ling_data.shape
ling_data.describe()

ling_data[6].value_counts()

# Visualizing the dataset
x = ling_data[0]
y = ling_data[6]

plt.scatter(x, y, c=y, cmap='Wistia')
plt.title('Scatter PLot of Logistic Regression')
plt.show()

# Splitting the dataset
x = ling_data.drop(columns=6, axis=1)
y = ling_data[6]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=1)

"""### **Methods**
##### **Logistic Regression**
Logistic regression is a statistical method for predicting binary outcomes from data. It is a supervised learning algorithm that is used for classification. In logistic regression, the dependent variable is binary or dichotomous, meaning it only contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). The goal of logistic regression is to find the best fitting model to describe the relationship between the dependent binary variable and one or more independent variables. The model is a linear combination of the independent variables and parameters (coefficients), where the independent variables are transformed using the logistic function. <br>The logistic function is given by: $$f(x) = \frac{1}{1 + e^{-x}}$$ <br> The output of the logistic function is a value between 0 and 1, which can be interpreted as the probability of the dependent variable being 1. To estimate the parameters in the logistic regression model, we can use maximum likelihood estimation. This involves finding the values of the parameters that maximize the likelihood function, which is a measure of the probability of the observed data given the model and the parameters. Once the parameters have been estimated, we can use the model to make predictions about the probability of the dependent variable being 1 for new data. We can also use a threshold value to classify the data into either class 0 or class 1. For example, if we set the threshold at 0.5, then a probability of 0.51 would be classified as class 1, and a probability of 0.49 would be classified as class 0.<br> In summary, logistic regression is a statistical method for predicting binary outcomes from data. It is a supervised learning algorithm that estimates the parameters of a linear combination of independent variables using the logistic function, and uses these estimates to make predictions about the probability of the dependent variable being 1.
"""

model = LogisticRegression()
model.fit(x_train, y_train)

x_train_predict = model.predict(x_train)
training_data_acc = accuracy_score(x_train_predict, y_train)

print(f'Training data accuracy: {training_data_acc}')

input_data = (17,2,2,2,1,8)
input_data_as_array = np.asarray(input_data)
input_data_reshape = input_data_as_array.reshape(1, -1)
predict = model.predict(input_data_reshape)

if predict[0] == '0':
  print('Intendency to become multilingual')
else:
  print('Tendency to become multilingual')

"""##### **Confusion Matrix**
A confusion matrix is a table that is used to describe the performance of a classification model on a set of test data for which the true values are known. It allows you to visualize the predictions made by the model, and compare them to the true values. The confusion matrix is a useful tool for understanding the errors made by the model, and for identifying patterns in the errors.
 <br> The confusion matrix has four main diagonal cells (top left, top right, bottom left, bottom right) and four off-diagonal cells (top left, top right, bottom left, bottom right). The main diagonal cells represent the number of correctly classified instances, while the off-diagonal cells represent the number of misclassified instances. The main diagonal cells are often referred to as true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).
<br> The formula for a confusion matrix is:
<br> TP: True positive (correctly classified as positive)
<br> TN: True negative (correctly classified as negative)
<br> FP: False positive (incorrectly classified as positive)
<br> FN: False negative (incorrectly classified as negative)
<br> In summary, the confusion matrix is a useful tool for evaluating the performance of a classification model, and for understanding the errors made by the model. It allows you to calculate a variety of metrics to understand the strengths and weaknesses of the model, and to identify patterns in the errors made by the model.
"""

disp = plot_confusion_matrix(model, x_test, y_test, cmap='Wistia', values_format='.3g')

disp.confusion_matrix

"""### **References**
1. Scikit-Learn Developers (2007-2022). BSD License- Logistic Regression.
2. Scikit-Learn Developers (2007-2022). BSD License- Confusion Matrix. 
3. John Hunter, Darren Dale, Eric Firing, Michael Droettboom and the Matplotlib Development Team (2012-2022).
4.  The Open Journal, Seaborn: Statistical Data Visualization, Michael L. Waskom (2012-2022).
5. NumPy Steering Council, NumPy, GitHub, BSD License (2022).
6. David W. Hosmer, Stanley Lemeshow, Rodney X. Sturdivent, Applied Logistic Regression (2013).
7. Machine Learning Mastery (2020-2022).
8. Andrew Plummer, The Beginner's Guide to Logistic Regression (2020).

### **Acknowledgemens**
We thank our mentor, Rajan Tripathi, for his continued guidance throughout the independent research and for his help in testing and planning the design for our machine learning model.
"""